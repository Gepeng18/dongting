由于现代JVM对象分配和gc效率都很高，一般来说现在的JVM已经不太需要对象池了，对于小对象来说，一个全局的对象池要保证线程安全，它可能是负优化，还不如直接new。不过对于ByteBuffer这种可大可小的的东西来说，需要视情况而定。小的buffer比如几十个字节确实没有太大必要，但大的buffer可能1M以上，这就和几十个字节完全不是一个量级的东西。IO操作时，经常需要用到数组去接收数据，典型的buffer大小是几KB到上百KB，我认为大于1KB就很有意义了。
由于buffer可大可小，它的对象池涉及到内存分配的复杂算法，netty里面就实现了非常完善的对象池，我没有研究过jemalloc，时间精力也不允许，就只好先摆烂。在去年我就实现了SimpleByteBufferPool，把不同大小的Buffer分别放到不同的池子里面，分配算法简单粗暴。缺点是空间利用率不高，可能会出现8K的池子用尽了而16K的池子还有的情况，它也不会把一个16K拆成两个8K的来用。好处是因为简单所以时间复杂度极低，分配极快。直接分配小于等于64字节的buffer，耗时小于9纳秒，分配65字节的buffer耗时27纳秒，256字节35纳秒，1024字节104纳秒，16KB需要1188纳秒。使用SimpleByteBufferPool命中的情况下，耗时在6~11纳秒。
SimpleByteBufferPool默认不是线程安全的，之前的文章也提到过，dongting很多地方是单线程处理的，raft线程和io线程都有自己的对象池，在这种场景下它就非常合适了。
对于大buffer来说，SimpleByteBufferPool空间利用率不足的缺点更加明显，多个线程持有多个大对象池，内存开销很大。所以TwoLevelPool就应运而生，将buffer按大小分为两级，小对象池线程独享，大对象池则是全局的，通过加锁来分配和释放。大对象创建开销很大，加锁这点开销相比就忽略不计了，全局的对象池可以提升利用率和命中率。
实际上TwoLevelPool有三级，当buffer小于某个阈值的时候直接分配，不使用对象池。
还有一个问题，数据有时候还是会跨线程使用，比如IO线程中解码的数据，又交给了其它线程使用，怎么还呢？TwoLevelPool的toReleaseInOtherThreadInstance方法提供了这个能力，它返回的还是一个TwoLevelPool实例，这是实例分配buffer的时候必须在owner线程中执行，释放buffer的时候，会将一个任务放到owner线程的任务队列中，然后还是由owner线程来释放。
为了更加方便的对ByteBuffer的引用进行计数，引入了RefBuffer，它继承RefCount，内部包含一个ByteBuffer字段。在多线程场景下，RefCount的retain/release会对应getAndAdd/weakCAS操作，为了节省这点开销，RefCount实例可以构造为plain模式，plain模式的RefCount只能在单线程场景中使用，使用者构造的时候根据情况选择。实际上，如果没有多次retain/release，A线程借出B线程归还其实也可以用plain模式，当A线程借出后将对象传递给B线程的时候，happens before原则已经确保了B线程能看见A线程的数据，并且保证了借出在归还之前，归还的时候反正也是写入A线程的队列，最后由A来归还的，这里就没有其它的竞争了。
如果需要使用RefBuffer，应该通过RefBufferFactory，它其实是ByteBufferPool的一个包装，借出的不是ByteBuffer，而是RefBuffer，这样就可以对其进行引用计数了。
最后总结一下，借了对象要还，这么简单的道理，说起来容易做起来难，不然自动gc也不会成为大部分编程语言的标配了。在现在dongting的实现里面，对象忘记归还是小事，反正有gc兜底，偶尔漏点性能都不会有多大损失。最怕的就是还多了，或者已经还了的对象继续使用，会发生什么事情，简直不敢想。所以我也没在所有的地方应用池化ByteBuffer，有些地方现在就是随便先写完，想着等以后再到主路径上面找核心瓶颈点优化；但是有时候呢又会想的比较多。如果你发现dongting里面有的地方性能抠的特别细，有些地方似乎又很随意，那可能是因为我在摇摆。
