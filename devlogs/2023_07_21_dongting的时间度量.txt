程序中最常使用的衡量时间的方式是毫秒数，比如Java中的System.currentTimeMillis()，它还可以用来构造日期对象，然而在严格衡量时间的流逝方面，它并不胜任。原因在于毫秒数无法保证单调性，当NTP服务或者管理员重设系统时间，系统时间可能会发生大幅漂移，单调性也可能被破坏。
如果时间的正确性不能保证，rpc调用可能会莫名其妙的超时（甚至调用刚发起就超时），一些基于超时的保活机制也会失效，从而威胁到系统的稳定运行，在一些严格的场景，极端情况甚至能破坏一致性（比如raft lease读就依赖于时间的正确性）。
好在我们有更好的方法：System.nanoTime()。这个方法很多人不爱用，因为它返回的数字没有实际意义（不像currentTimeMillis返回的是1970年来的毫秒数），不能用来转换成时间或日期对象，只能用来衡量同一个JVM内两次调用之间的时间差，如果JVM重启了，同一个机器上前后两个进程分别生成的nanoTime也是没法比较的。但它能保证单调性，有这一点就足够了。
在dongting中，DtTime类基于nanoTime方法，来衡量时间的流逝或者判断超时。DtTime对象里面两个字段，createTime、deadline都是final的，构造好以后随时可以衡量当前距离构造时间过去了多久，有没有超时。在调用链中，多个环节都要检查是否超时，DtTime的好处是，不用每次做减法，计算还剩多少时间，再把新的剩余时间传递到下个方法，缺点是要多创建一个对象。以rpc模块为例，dongting会在以下地方检查是否超时：
1、client在发起调用之前，通过tryAcquire获取Semaphore（限流措施）的时候。
2、client发起的请求在io队列在排队完成，准备写入socket（给server）的时候
3、server端处理请求之前
4、server端response在io队列中排队完成，准备写入socket（给client）的时候
5、client定期清理超时的请求
由于client和server的nanoTime()是不能直接比较的，从client发送到server接收这段时间无法测量，dongting也不使用系统时间（currentTimeMillis）来做这个测量，因为系统时间无法精确校准，且不受我们控制。dongting的做法是，请求在client的io队列完成排队，即将写入socket时，将剩余的时间作为一个参数传给server，server以接收时间开始计时，路上的时间就忽略了。
性能方面，nanoTime()比currentTimeMillis()开销大很多，通过简单测量大约需要30纳秒，如果某个核心逻辑是单线程处理（比如加了锁，或者单线程模型），每次处理时调用一次nanoTime()，那么在100万TPS的情况下，光调用这个方法的开销就会达到30毫秒/秒，也就是3%，但实际上处理过程中调用nanoTime()远远不止一次，不光超时，很多其它判断也需要取时间，按放大10倍算的话，开销就会达到30%，所以dongting又创造了Timestamp类。
Timestamp是个单线程对象，它牺牲精度来保证性能，缓存nanoTime()的结果，且仍然保证单调递增性。刷新时先用currentTimeMillis()来检查是否有必要刷新，然后再调用nanoTime()，即便如此，刷新通常也只在event loop开始时，或执行了耗时操作后才调用一次，大大减少了刷新的开销。不同的Timestamp实例生成的纳秒数无法精确比较。
现在看起来万事俱备，不过还有两个小小的问题需要注意。
第一点，nanoTime()返回的数字是不保证不溢出的，所以如果两个返回值t1和t2如果要比较的话，不能用大于或小于来直接比，而是应该比较差值，比如：if(t2-t1>=0)
第二点，nanoTime()真的能够保证单调性吗？从Java的设计来说应该是这样的，但它在不同的平台下有不同的实现，而且可能会有bug（见stackoverflow.com的"Is System.nanoTime() completely useless?"），为了更好的保证单调性，可以在Timestamp中增加一些检查，如果由于bug真的发生了回退，做个兜底。这个工作现在还没有做，我准备今天试着优化一下这里，有兴趣的可以看看下一个提交。